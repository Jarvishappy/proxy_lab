2015-7-2
Milestone
1. 先实现一个最最简单的echo client, echo serve，不带error handling
2. 逐步增强功能，实现最简单的的proxy
3. 改造成多线程版本

2015-7-4
实现了最简单的echo client, echo server。
1. 读socket的时候，read()返回0代表什么？
答：表示peer socket关闭了(EOF, no more data to be read)。如果是server检测到
这个事件，那么server就应该把clientfd给关闭。server可以继续往这个clientfd写入数据，
不会报错。

2. write()一个closed socket，会报什么错?
答：write() return -1 and set errno to EBADF. proxy lab的handout pdf中说的是EPIPE

3. read()一个closed socket会报什么错？
答：read() return -1 and set errno to EBADF. proxy lab的handout pdf中说的是ECONNRESET


2015-7-5
实现了proxy的核心功能: proxy。
代码结构很混乱，有很多重复的代码(读取request和response的header，body的代码可以提取
成一个function)。
考虑能否用select()消除重复代码，让代码变得更加简洁。

proxy lab的part1完成的差不多了。proxy的功能已经实现，代码也整理了一下，变得比较简洁了。但是使用telnet测试GET
http://www.taobao.com/ HTTP/1.1时报了segmentation fault。


2015-7-11
有多个bug导致了segmentation fault：
1. parse_request_line()的delim=strchr(io_buf->linebuf, ' ');
这一句，strchr()没有找到' '，返回NULL，然后下面没有判断delim是否不为NULL，直接*delim='\0'了

2. 然后，根本的原因竟然是在send_body()里，send_body需要从target server的响应中读出body，
然后再写回给浏览器，读的时候我是一次性读content_len个字节的，但是很明显，content_len有时
候会比MAXBUF大，所以这里也发生了segment fault，需要用一个循环每次至多读取MAXBUF个字节到Buffer
中，然后用rio_readnb的返回值作为rio_writen的最后一个参数。


现在是没有segmentation fault了，但是经常会blocked在rio_read():590的read()上啊
解决办法：
1. 把socket搞成non-blocking的，这样子read()读不到数据的时候就不会一直blcoked住了！
2. 不使用buffered的IO，只用unbuffered的read()


2015-7-12
1. 多线程环境下，如何保证每个thread有private的errno，不修改别的thread的errno？
答：errno在Linux下是thread-safe的，POSIX标准也规定了errno必须是thread-specific的。

1. Thread per connection
每次accept到一个connection，就创建一个thread，把fd丢给thread

2. Thread per request


先实现最简单的thread per connection

2015-7-18
今天outing，没有网络，测试好麻烦。在ubuntu里开了个python web server，用telnet测了一下，
接收到新的连接之后可以成功的创建worker thread。


2015-8-8
1. Proxy转发请求过去之后，返回的响应是Bad Request
多线程版本把请求转发给target server（如sina.com.cn, aol.com）之后，收到的响应分别是
Access Denied，Bad Request。于是我就推测有可能是proxy发过去的HTTP报文格式不对，导致
服务端无法正常解析。基于Principle of Confirmation，我需要去验证proxy发给target server
的报文，于是我就用Wireshark来抓包，需要注意的是在启动capture之前可以在interface上设置
capture filter，而capture filter的语法跟display filter的语法是不同的！

最初我的display filter指定了tcp.port==15213（15213是proxy的listen port），这样只能
capture到浏览器发送给proxy的报文，而无法capture到proxy发送给target server的报文。
要获取proxy转发过去的报文，我需要知道proxy_worker()中Open_clientfd()打开的socket
的port。这样我才能过滤去我真正想要的报文。

最后发现proxy发过去的报文果然是有问题的，request line的最后少了CRLF：

正确的：GET / HTTP/1.1\r\n
错误的：GET / HTTP/1.1

原因是parse_request_line()中的这一句:

    sscanf(io_buf->linebuf, "%s %s %s", reqline->method, reqline->uri, reqline->versionCRLF);

versionCRLF中存的是"HTTP/1.1"而不是"HTTP/1.1\r\n"，根本原因是scanf的%s只匹配非空白符，空白符之后的直接被忽略了。
再举个例子：
scanf("%s", input) 这一句从stdin读入一个字符串到input中。
假设你输入的是hello world，那么最终存到input中的是"hello"


2. www.aol.com返回的响应中没有Content-Length头
原因是server端采用的是chunked encoding的方式返回响应，由HTTP头Transfer-Encoding: chunked指定。
HTTP标准规定server采用chunked encoding的方式返回响应时，是没有Content-Length头的，因为
server把一整个完整的响应拆分成了一个一个的chunk，此时HTTP Response的格式为：

HTTP-Response  =   HTTP-Headers
                   CRLF
                   Chunked-Body

Chunked-Body   =   *chunk
                   last-chunk
                   trailer-part
                   CRLF

chunk          = chunk-size *WSP [ chunk-ext ] CRLF
                 chunk-data CRLF
chunk-size     = 1*HEXDIG
chunk-data     = 1*OCTET ; a sequence of chunk-size octets
last-chunk     = 1*("0") *WSP [ chunk-ext ] CRLF

chunk-size就是一个十六进制数，表示的是这个chunk的大小。




